{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3, 2022201027\n",
    "### NLP Q1\n",
    "\n",
    "_Bert tweet model for regressing the sentiment scores of tweets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, BertPreTrainedModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>Why does Candice constantly pout #GBBO üíÑüòí</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>@redBus_in #unhappy with #redbus CC, when I ta...</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>@AceOperative789 no pull him afew weeks ago, s...</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>I'm buying art supplies and I'm debating how s...</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>@sainsburys Could you ask your Chafford Hundre...</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5755 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  score\n",
       "0     How the fu*k! Who the heck! moved my fridge!.....  0.938\n",
       "1     So my Indian Uber driver just called someone t...  0.896\n",
       "2     @DPD_UK I asked for my parcel to be delivered ...  0.896\n",
       "3     so ef whichever butt wipe pulled the fire alar...  0.896\n",
       "4     Don't join @BTCare they put the phone down on ...  0.896\n",
       "...                                                 ...    ...\n",
       "5750          Why does Candice constantly pout #GBBO üíÑüòí  0.396\n",
       "5751  @redBus_in #unhappy with #redbus CC, when I ta...  0.604\n",
       "5752  @AceOperative789 no pull him afew weeks ago, s...  0.479\n",
       "5753  I'm buying art supplies and I'm debating how s...  0.375\n",
       "5754  @sainsburys Could you ask your Chafford Hundre...  0.438\n",
       "\n",
       "[5755 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "tweets = pd.read_csv(\"data/q1/train.csv\", index_col=0)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=3130234afe0c0e76cfa3cfadaedfb69e0effe1eee4d1dbcab4810905cc53d211\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##',\n",
       " tensor([[    0,   203,     6, 11644,   110,   536,    12,   449,     6,  6048,\n",
       "             12,  1985,    23,  7489,    12,    28,   151,     8,  4251,     6,\n",
       "          30598,  1279,     4,    85,  2486,    85,   623,   465,   465,     2]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base', normalization=True) # or 'roberta-base'\n",
    "tweets['text'][0], torch.tensor([tokenizer.encode(tweets['text'][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'input_ids': tensor([[   0,  203,    6,  ...,    1,    1,    1],\n",
       "          [   0,  180,   23,  ...,    1,    1,    1],\n",
       "          [   0,    5,    8,  ...,    1,    1,    1],\n",
       "          ...,\n",
       "          [   0,    5,   80,  ...,    1,    1,    1],\n",
       "          [   0,    8,   40,  ...,    1,    1,    1],\n",
       "          [   0,    5, 1373,  ...,    1,    1,    1]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " '_encodings': None,\n",
       " '_n_sequences': None}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the whole train set\n",
    "train_encodings = tokenizer(list(tweets['text'].values), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "train_encodings.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5755, 56])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.data['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# def tokenize_text(text):\n",
    "#     return tokenizer(text, add_special_tokens=True)\n",
    "# train_tokens = tweets[\"text\"].apply(tokenize_text)\n",
    "# train_tensors = [torch.tensor(token) for token in train_tokens]\n",
    "\n",
    "# max_size = max([t.size(0) for t in train_tensors])\n",
    "\n",
    "# # Pad the shorter tensors with zeros\n",
    "# padded_tensors = [torch.cat([t, torch.zeros(max_size - t.size(0))]) for t in train_tensors]\n",
    "\n",
    "# train_encodings = tokenizer(list(tweets['text'].values), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(TensorDataset(train_encodings.data['input_ids'], train_encodings.data['attention_mask'],\n",
    "                                train_encodings.data['token_type_ids'], torch.tensor(tweets[\"score\"].values)), \n",
    "                                batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class BertRegresser(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(BertRegresser, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        # print(self.bert.config.hidden_size)\n",
    "        self.fcn = nn.Linear(self.bert.config.hidden_size, 256)\n",
    "        self.ff1 = nn.Linear(256,128)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.ff2 = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        #Feed the input to Bert model to obtain contextualized representations\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        #Obtain the representations of [CLS] heads\n",
    "        logits = outputs.last_hidden_state[:,0,:]\n",
    "        output = torch.relu(self.fcn(logits))\n",
    "        # output = self.relu1(output)\n",
    "        output = self.ff1(output)\n",
    "        output = self.tanh(output)\n",
    "        out = self.ff2(output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# config = AutoConfig.from_pretrained('vinai/bertweet-base')\n",
    "# config.num_labels = 1\n",
    "# config.problem_type = \"regression\"\n",
    "model = BertRegresser('vinai/bertweet-base')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertRegresser(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fcn): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (ff1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (ff2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78458cb26a5748c2879beead34009f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19875fa9e07466e84840e354d6e3b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37f5b57e6434e2c8241dc790e8ae4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa30041eeb44841b961ea9bc3b0793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee6ebd6cab147ed853807fb328d5aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0374\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for input_ids, attention_masks, token_type_ids, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # print(labels.size(), input_ids.size())\n",
    "        input_ids, attention_masks, labels, token_type_ids = input_ids.to(device), attention_masks.to(device), labels.to(device), token_type_ids.to(device)\n",
    "        output = model(input_ids, attention_masks, token_type_ids)\n",
    "        loss = criterion(output.squeeze(1).float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.cpu().item()\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './bertweet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "test_encodings = tokenizer(list(test_tweets['text'].values), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_loader = DataLoader(TensorDataset(test_encodings.data['input_ids'], test_encodings.data['attention_mask'],\n",
    "                                test_encodings.data['token_type_ids'], torch.tensor(test_tweets[\"score\"].values)), \n",
    "                                batch_size=1, shuffle=True)\n",
    "\n",
    "# test_loader = DataLoader(TensorDataset(torch.stack(padded_tensors), torch.tensor(test_tweets[\"score\"].values)), \n",
    "#                                 batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7967362136e463b83390e3eec4a1768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2010\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "import math\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    # total_samples = 0\n",
    "    for input_ids, attention_masks, token_type_ids, labels in tqdm(test_loader):\n",
    "        input_ids, attention_masks, labels, token_type_ids = input_ids.to(device), attention_masks.to(device), labels.to(device), token_type_ids.to(device)\n",
    "        output = model(input_ids, attention_masks, token_type_ids)\n",
    "        loss = criterion(output.squeeze(1).float(), labels.float())\n",
    "        total_loss += loss.cpu().item()\n",
    "        # total_samples += len(labels)\n",
    "    test_loss = total_loss / len(test_loader)\n",
    "    rmse = math.sqrt(test_loss)\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n"
     ]
    }
   ],
   "source": [
    "# labels = [\"arts and culture\", \"business and entrepreneurs\", \"pop culture\", \"daily life\", \"sports and gaming\", \"science and technology\"]\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report as clr\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a313978c-0252-44fd-9cd1-fe1f14778d8e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The {@Clinton LumberKings@} beat the {@Cedar R...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516324419866624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major sidenote of the MSU game: How about the ...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516407135522816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would rather hear Eli Gold announce this Aub...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516440690176006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Someone take my phone away, I‚Äôm trying to not ...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516543387709440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A year ago, Louisville struggled to beat an FC...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516620466429953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>#NowPlaying Leaving in the Morning - Chicken D...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2</td>\n",
       "      <td>pop_culture</td>\n",
       "      <td>1300161140828368897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>A little bit of humour for #politas this morni...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>3</td>\n",
       "      <td>daily_life</td>\n",
       "      <td>1300190823863083008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>TheRealDimmak is live on YouTube (Call of Duty...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1300220478716547072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>. {{USERNAME}} :  RPT #Sinopec posts first hal...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>business_&amp;_entrepreneurs</td>\n",
       "      <td>1300221757824139264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>Facilitating 1st grade over here this morning....</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>3</td>\n",
       "      <td>daily_life</td>\n",
       "      <td>1300462769024663553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3598 rows √ó 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a313978c-0252-44fd-9cd1-fe1f14778d8e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a313978c-0252-44fd-9cd1-fe1f14778d8e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a313978c-0252-44fd-9cd1-fe1f14778d8e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   text        date  label  \\\n",
       "0     The {@Clinton LumberKings@} beat the {@Cedar R...  2019-09-08      4   \n",
       "1     Major sidenote of the MSU game: How about the ...  2019-09-08      4   \n",
       "2     I would rather hear Eli Gold announce this Aub...  2019-09-08      4   \n",
       "3     Someone take my phone away, I‚Äôm trying to not ...  2019-09-08      4   \n",
       "4     A year ago, Louisville struggled to beat an FC...  2019-09-08      4   \n",
       "...                                                 ...         ...    ...   \n",
       "3593  #NowPlaying Leaving in the Morning - Chicken D...  2020-08-30      2   \n",
       "3594  A little bit of humour for #politas this morni...  2020-08-30      3   \n",
       "3595  TheRealDimmak is live on YouTube (Call of Duty...  2020-08-30      4   \n",
       "3596  . {{USERNAME}} :  RPT #Sinopec posts first hal...  2020-08-30      1   \n",
       "3597  Facilitating 1st grade over here this morning....  2020-08-31      3   \n",
       "\n",
       "                    label_name                   id  \n",
       "0              sports_&_gaming  1170516324419866624  \n",
       "1              sports_&_gaming  1170516407135522816  \n",
       "2              sports_&_gaming  1170516440690176006  \n",
       "3              sports_&_gaming  1170516543387709440  \n",
       "4              sports_&_gaming  1170516620466429953  \n",
       "...                        ...                  ...  \n",
       "3593               pop_culture  1300161140828368897  \n",
       "3594                daily_life  1300190823863083008  \n",
       "3595           sports_&_gaming  1300220478716547072  \n",
       "3596  business_&_entrepreneurs  1300221757824139264  \n",
       "3597                daily_life  1300462769024663553  \n",
       "\n",
       "[3598 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"data/q2/tweet_topics.csv\", index_col=0)\n",
    "\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sports_&_gaming', 'pop_culture', 'arts_&_culture', 'daily_life',\n",
       "       'business_&_entrepreneurs', 'science_&_technology'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = tweets.label.unique()\n",
    "tweets.label_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tweets = tweets.drop_duplicates(subset=['text']) # Remove duplicate tweets\n",
    "tweets['text'] = tweets['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d9498f8a-869b-4fcf-93c8-a79ef32e0056\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{@Clinton LumberKings@} beat {@Cedar Rapids Ke...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516324419866624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Major sidenote MSU game: media team making cus...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516407135522816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would rather hear Eli Gold announce Auburn gam...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516440690176006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Someone take phone away, I‚Äôm trying look {@Chi...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516543387709440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year ago, Louisville struggled beat FCS oppone...</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1170516620466429953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>#NowPlaying Leaving Morning - Chicken Diamond ...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2</td>\n",
       "      <td>pop_culture</td>\n",
       "      <td>1300161140828368897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>little bit humour #politas morning. Waratah ci...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>3</td>\n",
       "      <td>daily_life</td>\n",
       "      <td>1300190823863083008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>TheRealDimmak live YouTube (Call Duty Black Op...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>4</td>\n",
       "      <td>sports_&amp;_gaming</td>\n",
       "      <td>1300220478716547072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>. {{USERNAME}} : RPT #Sinopec posts first half...</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>business_&amp;_entrepreneurs</td>\n",
       "      <td>1300221757824139264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>Facilitating 1st grade morning. take digital l...</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>3</td>\n",
       "      <td>daily_life</td>\n",
       "      <td>1300462769024663553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3598 rows √ó 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9498f8a-869b-4fcf-93c8-a79ef32e0056')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d9498f8a-869b-4fcf-93c8-a79ef32e0056 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d9498f8a-869b-4fcf-93c8-a79ef32e0056');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   text        date  label  \\\n",
       "0     {@Clinton LumberKings@} beat {@Cedar Rapids Ke...  2019-09-08      4   \n",
       "1     Major sidenote MSU game: media team making cus...  2019-09-08      4   \n",
       "2     would rather hear Eli Gold announce Auburn gam...  2019-09-08      4   \n",
       "3     Someone take phone away, I‚Äôm trying look {@Chi...  2019-09-08      4   \n",
       "4     year ago, Louisville struggled beat FCS oppone...  2019-09-08      4   \n",
       "...                                                 ...         ...    ...   \n",
       "3593  #NowPlaying Leaving Morning - Chicken Diamond ...  2020-08-30      2   \n",
       "3594  little bit humour #politas morning. Waratah ci...  2020-08-30      3   \n",
       "3595  TheRealDimmak live YouTube (Call Duty Black Op...  2020-08-30      4   \n",
       "3596  . {{USERNAME}} : RPT #Sinopec posts first half...  2020-08-30      1   \n",
       "3597  Facilitating 1st grade morning. take digital l...  2020-08-31      3   \n",
       "\n",
       "                    label_name                   id  \n",
       "0              sports_&_gaming  1170516324419866624  \n",
       "1              sports_&_gaming  1170516407135522816  \n",
       "2              sports_&_gaming  1170516440690176006  \n",
       "3              sports_&_gaming  1170516543387709440  \n",
       "4              sports_&_gaming  1170516620466429953  \n",
       "...                        ...                  ...  \n",
       "3593               pop_culture  1300161140828368897  \n",
       "3594                daily_life  1300190823863083008  \n",
       "3595           sports_&_gaming  1300220478716547072  \n",
       "3596  business_&_entrepreneurs  1300221757824139264  \n",
       "3597                daily_life  1300462769024663553  \n",
       "\n",
       "[3598 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both raw and preprocessed tweets gave same zero-shot **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2ab2cef074452592bb3398f82e16b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "y_true = tweets.label_name\n",
    "y_pred = []\n",
    "\n",
    "# for index,tweet in tqdm(tweets.iterrows()):\n",
    "#     # print(tweet['text'])\n",
    "#     result = classifier(tweet, labels)\n",
    "#     # print(labels[np.argmax(result['scores'])])\n",
    "#     y_pred.append(labels[np.argmax(result['scores'])])\n",
    "\n",
    "for i in tqdm(range(0, len(tweets), batch_size)):\n",
    "    batch = tweets.iloc[i:i+batch_size]\n",
    "    batch_results = classifier(batch.text.tolist(), labels)\n",
    "    batch_y_pred = [labels[np.argmax(result['scores'])] for result in batch_results]\n",
    "    y_pred.extend(batch_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        57\n",
      "           1       0.00      0.00      0.00       151\n",
      "           2       0.00      0.00      0.00      1378\n",
      "           3       0.00      0.00      0.00       605\n",
      "           4       0.34      1.00      0.51      1217\n",
      "           5       0.00      0.00      0.00       190\n",
      "\n",
      "    accuracy                           0.34      3598\n",
      "   macro avg       0.06      0.17      0.08      3598\n",
      "weighted avg       0.11      0.34      0.17      3598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clr(y_true.values, np.array(y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the zero-shot pipeline gives poor accuracy for classes other than sports and technology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Biases in bert-base-uncased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of caste axis of disparity, we hardly observe any consistent bias in the BERT base model so we switched to the DistilBERT wherein we clearly see demarcations in the top 5 mask substitutions. The other 2 axes show bias in BERT base-uncased itself.\n",
    "\n",
    "We can note that the caste setting is not so much prevalent in the training data fed to this model which is primarily dominant with western discourse, whereas gender biases appears more commonly as historical stereotypes and religious biases more commonly as more recent controversial news texts which has influenced the following predictions.\n",
    "\n",
    "We collect the predictions from the inference API of hugging face and present the results below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caste](caste_bias.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![religion](religion_bias.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gender](gender_bias.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Q4\n",
    "\n",
    "_Propensity score v/s classification model_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A propensity score model differs from a standard classification model in that it aims to ensure the distribution over all the potential confounder variables is same or similar for samples belonging to the treatment group as well as the control group. Thus it indirectly reports the probability that a sample with a set of features will exhibit a certain behaviour or preference towards treatment.\n",
    "</p>\n",
    "<p>Unlike a classification task, it doesn't aim to make a decision boundary for separability, but rather check that the probability of getting treated for the similarly behaving samples be similarly distributed across all the samples. This is verified by plotting the distribution of treatment and control samples against the propensity scores extracted by fitting the data on the intervention events occured or not(ground truths), and checking that it largely overlaps for both groups.</p>\n",
    "<p>The outcome variable of a propensity model is binary and the independent variables are usually related to demographics or transactions (at least in the first stage) wherease for a classification model, the outcome variables are categorical and the independent variables could be a set of singular or compositional features.</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['Cabin'][1])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare\n",
       "0       3.0  1.0  22.000000    1.0    0.0   7.2500\n",
       "1       1.0  0.0  38.000000    1.0    0.0  71.2833\n",
       "2       3.0  0.0  26.000000    0.0    0.0   7.9250\n",
       "3       1.0  0.0  35.000000    1.0    0.0  53.1000\n",
       "4       3.0  1.0  35.000000    0.0    0.0   8.0500\n",
       "..      ...  ...        ...    ...    ...      ...\n",
       "886     2.0  1.0  27.000000    0.0    0.0  13.0000\n",
       "887     1.0  0.0  19.000000    0.0    0.0  30.0000\n",
       "888     3.0  0.0  14.666667    1.0    2.0  23.4500\n",
       "889     1.0  1.0  26.000000    0.0    0.0  30.0000\n",
       "890     3.0  1.0  32.000000    0.0    0.0   7.7500\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def transform_port(x):\n",
    "    if x=='S':\n",
    "        return 1\n",
    "    elif x=='C':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "data['Cabin'] = data['Cabin'].apply(lambda x: 0 if type(x)==float else 1)\n",
    "data['Sex'] = data['Sex'].fillna(1).apply(lambda x: 1 if x=='male' else 0)\n",
    "# data['Embarked'] = data['Embarked'].apply(lambda x: transform_port(x))\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "\n",
    "T = 'Cabin'\n",
    "Y = 'Survived'\n",
    "X = data.columns.drop(['PassengerId','Name','Ticket','Embarked', T, Y])\n",
    "target = data[T]\n",
    "data = pd.DataFrame(imputer.fit_transform(data[X]), columns=X)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_model = LogisticRegression(C=1e6).fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ps = data.assign(propensity_score=ps_model.predict_proba(data)[:, 1])\n",
    "# data_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>propensity_score</th>\n",
       "      <th>cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.805332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.806255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.123583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.826855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.743272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  propensity_score  cabin\n",
       "0       3.0  1.0  22.000000    1.0    0.0   7.2500          0.006809      0\n",
       "1       1.0  0.0  38.000000    1.0    0.0  71.2833          0.805332      1\n",
       "2       3.0  0.0  26.000000    0.0    0.0   7.9250          0.010940      0\n",
       "3       1.0  0.0  35.000000    1.0    0.0  53.1000          0.806255      1\n",
       "4       3.0  1.0  35.000000    0.0    0.0   8.0500          0.006575      0\n",
       "..      ...  ...        ...    ...    ...      ...               ...    ...\n",
       "886     2.0  1.0  27.000000    0.0    0.0  13.0000          0.123583      0\n",
       "887     1.0  0.0  19.000000    0.0    0.0  30.0000          0.826855      1\n",
       "888     3.0  0.0  14.666667    1.0    2.0  23.4500          0.022287      0\n",
       "889     1.0  1.0  26.000000    0.0    0.0  30.0000          0.743272      1\n",
       "890     3.0  1.0  32.000000    0.0    0.0   7.7500          0.006704      0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ps['cabin'] = target\n",
    "data_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27168c8de40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data_ps.query(\"cabin==0\")[\"propensity_score\"], kde=False, label=\"Non Treated\")\n",
    "sns.distplot(data_ps.query(\"cabin==1\")[\"propensity_score\"], kde=False, label=\"Treated\")\n",
    "plt.title(\"Positivity Check\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27168857e20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove outliers\n",
    "data_ps[\"propensity_score_mid\"] = np.clip(data_ps[\"propensity_score\"], 0.15, 0.85)\n",
    "\n",
    "# Plot barplot\n",
    "sns.distplot(data_ps.query(\"cabin==0\")[\"propensity_score_mid\"], kde=False, label=\"Non Treated\")\n",
    "sns.distplot(data_ps.query(\"cabin==1\")[\"propensity_score_mid\"], kde=False, label=\"Treated\")\n",
    "plt.title(\"Positivity Check\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6398068640361284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = data_ps['propensity_score'].values\n",
    "logit_p = np.log(ps/(1-ps))\n",
    "caliper = 0.25 * np.std(logit_p)\n",
    "\n",
    "caliper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the caliper, it seems clear that there is a confounder variable in the sex of the passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881014fc96c14227ae5a2aa28cd282c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f90cb766bf473ab6bf1328c5490c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "control_ids = data_ps[data_ps['cabin']==0].index\n",
    "treatment_ids = data_ps[data_ps['cabin']==1].index\n",
    "\n",
    "matched_pairs = {}\n",
    "for tid in tqdm(treatment_ids):\n",
    "    matched_pairs[tid] = []\n",
    "    for cid in control_ids:\n",
    "        matched_pairs[tid].append((abs(data_ps['propensity_score'].iloc[tid] - data_ps['propensity_score'].iloc[cid]),cid))\n",
    "\n",
    "for tid in tqdm(treatment_ids):\n",
    "    matched_pairs[tid] = [i for i in matched_pairs[tid] if i[0]<caliper]\n",
    "\n",
    "matched_pairs_final = {}\n",
    "for k,v in matched_pairs.items():\n",
    "    matched_pairs_final[k] = min(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMD = {col:{'t_values':[],'c_values':[],'SMD':None} for col in X}\n",
    "\n",
    "for k,v in matched_pairs_final.items():\n",
    "    for col in X:\n",
    "        SMD[col]['t_values'].append(data_ps[col].iloc[k])\n",
    "        SMD[col]['c_values'].append(data_ps[col].iloc[v[1]])\n",
    "\n",
    "for k,v in SMD.items():\n",
    "    num = np.mean(v['t_values'])-np.mean(v['c_values'])\n",
    "    dom = ((np.std(v['t_values'])**2) + (np.std(v['c_values'])**2))/2\n",
    "    v['SMD'] = num/np.sqrt(dom)\n",
    "    print(k, v['SMD'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
